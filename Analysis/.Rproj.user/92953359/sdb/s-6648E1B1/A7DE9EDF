{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Data Clean\"\noutput: html_notebook\n---\n\n```{r}\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(forcats)\nlibrary(edgeR)\n```\n\n```{r}\nsetwd(\"/Users/edwards/Google Drive/RMB/Analyses/LifeCycle/Data/\")\nmap <- read.table(\"life_cycle_map.txt\", header = T, sep = \"\\t\")\ncounts <- read.table(gzfile(\"lifeCycleOtuTable.txt.gz\"), header = T, row.names = 1)\norg <- readRDS(\"~/RMB/Reference/organelle.rds\")\n```\n\n```{r}\ncounts.NoOrg <- counts[!row.names(counts)%in%org,]\nmap <- map[match(colnames(counts.NoOrg), map$SampleID),]\nmap$OriginalDepth <- colSums(counts)\nmap$FilteredDepth <- colSums(counts.NoOrg)\n```\n\n```{r}\nmap %>% \n  gather(Type, Depth, OriginalDepth:FilteredDepth) %>% \n  ggplot(aes(Depth, fill = Type)) +\n  geom_histogram() +\n  scale_x_log10() +\n  facet_grid(Site~Compartment)\n```\n\n```{r}\nmap %>% \n  mutate(discard = ifelse(FilteredDepth > 2000, \"yes\", \"no\")) %>% \n  group_by(discard) %>% \n  summarise(n())\n```\n\n```{r}\ncounts.NoOrg.goodSamples <- counts.NoOrg[,colSums(counts.NoOrg) >= 2000]\n```\n\n```{r}\nnon_zero <- function(x) sum(x > 0)\ncounts.NoOrg.goodSamples.goodOTUs <- counts.NoOrg.goodSamples[apply(counts.NoOrg.goodSamples, 1, non_zero) > 0.05*ncol(counts.NoOrg.goodSamples),]\nmap.goodSamples <- map[match(colnames(counts.NoOrg.goodSamples.goodOTUs), map$SampleID),]\ndim(counts.NoOrg.goodSamples)\ndim(counts.NoOrg.goodSamples.goodOTUs)\n```\n\nHow many sequences did we lose by removing low prevalence OTUs?\n```{r}\nmap.goodSamples$FinalDepth <- colSums(counts.NoOrg.goodSamples.goodOTUs)\nmap.goodSamples %>% \n  ggplot(aes(FilteredDepth - FinalDepth, FinalDepth, color = Compartment)) +\n  geom_point() +\n  scale_y_log10() +\n  scale_x_log10()\n```\n\n## TMM Normalization\n```{r}\notuL <- DGEList(counts.NoOrg.goodSamples.goodOTUs, lib.size = colSums(counts.NoOrg.goodSamples.goodOTUs))\notuL <- calcNormFactors(otuL)\ncounts.tmm <- cpm(otuL)\n```\n\n## Relative Abundance Normalization\n```{r}\ncounts.RA <- t(t(counts.NoOrg.goodSamples.goodOTUs) / colSums(counts.NoOrg.goodSamples.goodOTUs)) * 1000\n```\n\n## Make an object to keep everything in and save it\n```{r}\nlc.exp <- list(map = map.goodSamples, tmm = counts.tmm, ra = counts.RA)\nsave(lc.exp, file = \"lifeCylceExperiment.rda\")\n```\n\n## Also save the count tables as .tsv files\nI will later gzip the files in terminal\n```{r}\nwrite.table(counts.tmm, file = \"lifeCycle_OTU_table_TMM.tsv\", sep = \"\\t\", quote = F)\nwrite.table(counts.RA, file = \"lifeCycle_OTU_table_RA.tsv\", sep =\"\\t\", quote = F)\nwrite.table(map.goodSamples, file = \"lifeCycle_goodSamples_map.txt\", sep = \"\\t\", quote = F)\n```\n\n",
    "created" : 1489538741807.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4232260530",
    "id" : "A7DE9EDF",
    "lastKnownWriteTime" : 1489597100,
    "last_content_update" : 1489597100206,
    "path" : "~/Google Drive/RMB/Analyses/LifeCycle/Analysis/data_clean.rmd",
    "project_path" : "data_clean.rmd",
    "properties" : {
        "chunk_output_type" : "inline",
        "source_window_id" : "w1yrujo48ejox",
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}